\documentclass[journal]{IEEEtran}
\usepackage{amsmath,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{array}
\usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\usepackage{textcomp}
\usepackage{stfloats}
\usepackage{url}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{hyperref}
\hyphenation{op-tical net-works semi-conduc-tor IEEE-Xplore crypto-currency block-chain}

\begin{document}

\title{CryptoGuard-LLM: A Multi-Modal Deep Learning Framework for Real-Time Cryptocurrency Fraud Detection with Societal Impact Analysis}

\author{Naga~Sujitha~Vummaneni,~\IEEEmembership{Senior~Member,~IEEE,}
        Usha~Ratnam~Jammula,~\IEEEmembership{Member,~IEEE,}
        and~Ramesh~Chandra~Aditya~Komperla,~\IEEEmembership{Senior~Member,~IEEE}
\thanks{Manuscript received January 2026; revised [Date]; accepted [Date]. Date of publication [Date]; date of current version [Date]. \textit{(Corresponding author: Naga Sujitha Vummaneni.)}}
\thanks{N. S. Vummaneni is with Cornell University, Ithaca, NY 14853 USA (e-mail: nv262@cornell.edu; ORCID: 0009-0004-5492-9293).}
\thanks{U. R. Jammula is an Independent Researcher (e-mail: jammula.usha@gmail.com).}
\thanks{R. C. A. Komperla is an Independent Researcher.}
\thanks{Digital Object Identifier [DOI to be inserted by IEEE]}}

\markboth{IEEE Transactions on Information Forensics and Security}%
{Vummaneni \MakeLowercase{\textit{et al.}}: CryptoGuard-LLM}

\maketitle

\begin{abstract}
The exponential growth of cryptocurrency markets has created unprecedented opportunities for financial fraud, with losses exceeding \$6.4 billion globally in 2025 alone. This empirical study presents CryptoGuard-LLM, a novel multi-modal deep learning framework that integrates Large Language Models (LLMs), Graph Neural Networks (GNNs), and ensemble machine learning techniques for real-time detection of cryptocurrency-related cyber threats. Our framework processes heterogeneous data streams including blockchain transaction graphs, exchange order flows, social media sentiment, and dark web intelligence feeds. Through extensive experimentation on a dataset comprising 47.3 million transactions across Bitcoin, Ethereum, and 15 major altcoins collected between January 2024 and December 2025, we demonstrate that CryptoGuard-LLM achieves 96.8\% detection accuracy with a 94.7\% recall rate, significantly outperforming existing approaches. Beyond technical contributions, this research addresses critical societal implications including the disproportionate impact of cryptocurrency fraud on retail investors, regulatory compliance challenges across jurisdictions, and the evolving threat landscape posed by AI-augmented criminal operations. We provide actionable recommendations for policymakers, financial institutions, and individual users to mitigate cryptocurrency-related cybersecurity risks.
\end{abstract}

\begin{IEEEkeywords}
Blockchain security, cryptocurrency fraud detection, cybersecurity, financial crime prevention, graph neural networks, large language models, machine learning, regulatory technology.
\end{IEEEkeywords}

\section{Introduction}

\IEEEPARstart{T}{he} cryptocurrency ecosystem has undergone remarkable transformation since the introduction of Bitcoin in 2009, evolving from a niche technological experiment into a multi-trillion dollar asset class that intersects traditional finance, technology, and regulatory frameworks. As of January 2026, the total cryptocurrency market capitalization exceeds \$4.2 trillion, with over 420 million users worldwide engaging in digital asset transactions. However, this rapid growth has been accompanied by an equally concerning proliferation of sophisticated cyber threats that exploit the pseudonymous nature of blockchain transactions, the complexity of decentralized finance (DeFi) protocols, and the limited regulatory oversight across jurisdictions.

The financial and human cost of cryptocurrency-related fraud has reached alarming proportions. According to recent reports, cryptocurrency scams and thefts resulted in losses of \$6.4 billion in 2025, representing a 47\% increase from the previous year. These losses are not merely financial statistics; they represent devastating impacts on individuals who have lost life savings, small businesses that have been defrauded, and communities that have been targeted by sophisticated criminal enterprises. The democratization of financial services through cryptocurrency has simultaneously democratized exposure to financial crime, with retail investors being disproportionately affected by rug pulls, phishing attacks, and Ponzi schemes that would be less viable in traditional, regulated financial markets.

Traditional cybersecurity approaches have proven inadequate for addressing the unique challenges posed by cryptocurrency fraud detection. Rule-based systems fail to adapt to rapidly evolving attack vectors, while conventional machine learning models struggle with the high-dimensional, temporal, and graph-structured nature of blockchain data. Furthermore, the emergence of Large Language Models (LLMs) has created a double-edged sword: while these powerful AI systems can be leveraged for enhanced threat detection, they are also being exploited by malicious actors to generate sophisticated phishing content, create convincing fake project documentation, and automate social engineering attacks at unprecedented scale.

This paper presents CryptoGuard-LLM, a comprehensive multi-modal deep learning framework designed to address these challenges through the integration of state-of-the-art AI technologies. Our approach combines the semantic understanding capabilities of transformer-based LLMs with the structural analysis power of Graph Neural Networks (GNNs) and the proven effectiveness of ensemble machine learning methods. Importantly, our research extends beyond purely technical contributions to examine the broader societal implications of cryptocurrency fraud and the potential for AI-powered detection systems to protect vulnerable populations while respecting privacy and regulatory requirements.

\subsection{Research Questions and Contributions}

This study addresses three primary research questions: (1) How can multi-modal deep learning architectures be effectively designed to detect cryptocurrency fraud across heterogeneous data sources? (2) What are the performance trade-offs between detection accuracy, computational efficiency, and real-time processing requirements in cryptocurrency security systems? (3) How do cryptocurrency fraud patterns affect different demographic groups, and what policy interventions can mitigate these disparities?

Our contributions include: (a) the design and implementation of CryptoGuard-LLM, a novel framework achieving state-of-the-art performance on cryptocurrency fraud detection; (b) the creation of a comprehensive benchmark dataset with ground-truth labels for 47.3 million transactions; (c) empirical analysis of societal impacts including demographic disparities in fraud victimization; and (d) policy recommendations for regulators, industry practitioners, and individual users.

\section{Background and Related Work}

\subsection{Cryptocurrency Fraud Taxonomy}

Cryptocurrency fraud encompasses a diverse taxonomy of attack vectors that have evolved significantly since the early days of digital assets. For readers unfamiliar with this domain, we provide a brief summary of key fraud categories before discussing technical detection approaches.

Rug pulls represent the most financially damaging category, wherein project developers abandon a cryptocurrency project after attracting substantial investment, typically by removing liquidity from decentralized exchanges. In 2025, rug pulls accounted for approximately \$1.8 billion in losses. Phishing attacks targeting cryptocurrency users have become increasingly sophisticated, leveraging AI-generated content to create convincing fake websites, wallet interfaces, and customer support communications. Ponzi and pyramid schemes disguised as legitimate investment platforms continue to proliferate, often promising unrealistic returns through purported trading algorithms or mining operations. Exchange hacks and smart contract exploits represent technical attack vectors that target vulnerabilities in centralized and decentralized infrastructure respectively.

\subsection{Machine Learning in Blockchain Security}

The application of machine learning to blockchain security has progressed through several evolutionary stages. Early approaches employed classical supervised learning algorithms such as Random Forests and Support Vector Machines for transaction classification. Weber et al. \cite{b15} introduced the Elliptic dataset and demonstrated that gradient boosting methods could achieve approximately 77\% accuracy in identifying illicit Bitcoin transactions. Subsequent work by Hu et al. \cite{b6} explored the application of recurrent neural networks to capture temporal patterns in transaction sequences.

Graph Neural Networks have emerged as particularly suitable for blockchain analysis due to the inherent graph structure of transaction networks. Pareja et al. \cite{b11} introduced EvolveGCN for dynamic graph learning, while Liu et al. \cite{b8} demonstrated the effectiveness of heterogeneous graph transformers for cryptocurrency fraud detection. More recently, federated learning approaches have been proposed to enable collaborative model training while preserving the privacy of transaction data across multiple exchanges.

\subsection{Large Language Models in Cybersecurity}

The integration of Large Language Models into cybersecurity applications represents a paradigm shift in threat detection capabilities. Zhang et al. \cite{b17} conducted a comprehensive systematic review demonstrating that LLMs enhance threat detection through in-context learning and automated intelligence extraction. Domain-specific models such as SecureFalcon and CyberBERT have been fine-tuned on security corpora to improve performance on specialized tasks including vulnerability detection, malware analysis, and threat intelligence synthesis.

However, LLM deployment in security contexts introduces unique challenges. Greshake et al. \cite{b4} demonstrated vulnerabilities to prompt injection attacks that could compromise system integrity. Hallucination risks require careful validation of model outputs, particularly in high-stakes security decisions. Our work addresses these challenges through ensemble architectures that combine LLM outputs with verified blockchain data and external threat intelligence.

\section{Methodology}

\subsection{System Architecture}

CryptoGuard-LLM employs a four-layer architecture designed for scalable, real-time cryptocurrency fraud detection. Fig.~\ref{fig:architecture} illustrates the overall system design. The Data Collection Layer aggregates information from five primary sources: blockchain transaction data obtained through full-node implementations for Bitcoin and Ethereum, exchange API feeds providing order book and trade data from 12 major centralized exchanges, social media streams monitored for cryptocurrency-related content, threat intelligence feeds from industry consortiums, and dark web forum discussions relevant to cryptocurrency fraud.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig1_architecture.png}
\caption{CryptoGuard-LLM integrated security framework architecture showing data collection, processing, detection, and output layers.}
\label{fig:architecture}
\end{figure}

The ML/LLM Processing Layer implements our multi-modal analysis pipeline. Graph Neural Networks process the transaction graph structure, identifying anomalous patterns in fund flows and wallet interactions. A transformer-based encoder generates contextual embeddings for textual data including project whitepapers, social media posts, and forum discussions. GPT-4 integration provides semantic analysis for complex fraud narratives and generates human-readable explanations for detected threats. An ensemble classifier combines outputs from multiple models using a weighted voting mechanism calibrated on validation data.

\subsection{Graph Neural Network Component}

\textit{Technical summary for non-specialist readers: The Graph Neural Network component learns patterns from the network structure of cryptocurrency transactions. Just as social networks reveal relationships between people, transaction graphs reveal relationships between wallets and can expose suspicious patterns invisible to traditional analysis.}

We implement a heterogeneous graph attention network (HGAT) that processes transaction graphs with multiple node and edge types. Node features include wallet age, transaction frequency, average transaction value, and derived metrics such as the ratio of incoming to outgoing transactions. Edge features encode transaction timestamps, values, and gas prices (for Ethereum). The attention mechanism learns to weight neighbor contributions based on their relevance to fraud detection, enabling the model to focus on suspicious transaction patterns while filtering noise from legitimate activity.

\subsection{LLM Integration Strategy}

Large Language Models serve multiple roles within our framework. For threat intelligence processing, we employ a fine-tuned BERT model trained on 2.3 million labeled security documents to classify incoming threat reports and extract structured indicators of compromise. For semantic analysis of project documentation and social media content, we utilize GPT-4 through a carefully designed prompt engineering pipeline that includes explicit instructions for skepticism toward unrealistic claims and detection of common fraud narratives.

To mitigate hallucination risks, LLM outputs are validated against verified blockchain data and cross-referenced with multiple independent sources. A confidence calibration module estimates the reliability of LLM predictions based on input characteristics and historical accuracy patterns. High-stakes decisions trigger human analyst review before automated responses are initiated.

\subsection{Dataset Construction}

Our experimental dataset comprises 47.3 million transactions collected between January 2024 and December 2025 from Bitcoin, Ethereum, and 15 major altcoins. Ground-truth labels were obtained through a multi-stage annotation process combining automated heuristics, blockchain forensics, and manual expert review. Approximately 2.1\% of transactions were labeled as illicit, consistent with industry estimates of fraud prevalence.

\begin{table}[!t]
\caption{Dataset Statistics and Distribution}
\label{tab:dataset}
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Blockchain} & \textbf{Trans. (M)} & \textbf{Illicit (\%)} & \textbf{Time Period} \\
\midrule
Bitcoin & 18.7 & 1.8 & Jan 2024 -- Dec 2025 \\
Ethereum & 21.4 & 2.4 & Jan 2024 -- Dec 2025 \\
Altcoins (15) & 7.2 & 2.3 & Jan 2024 -- Dec 2025 \\
\midrule
\textbf{Total} & \textbf{47.3} & \textbf{2.1} & \textbf{24 months} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Implementation Details}

Following IEEE TIFS guidelines for deep learning reproducibility, we provide comprehensive implementation details. All experiments were conducted using PyTorch 2.1.0 with CUDA 12.1 on a cluster of eight NVIDIA A100 (80GB) GPUs.

\subsubsection{GNN Architecture}
The heterogeneous graph attention network consists of 4 message-passing layers with hidden dimension 256. Each layer uses multi-head attention with 8 heads. Node features are initialized using a 128-dimensional embedding layer. We employ LeakyReLU activation (negative slope = 0.2) after each layer, followed by batch normalization. Edge features are processed through a 2-layer MLP with dimensions [64, 128].

\subsubsection{BERT Fine-tuning}
We fine-tune \texttt{bert-base-uncased} (110M parameters) on our security corpus. Input sequences are tokenized with maximum length 512. We use AdamW optimizer with initial learning rate $2 \times 10^{-5}$, linear warmup over 10\% of training steps, and linear decay. Batch size is 32 with gradient accumulation over 4 steps. Training runs for 3 epochs with early stopping based on validation F1-score (patience = 5).

\subsubsection{Ensemble Classifier}
The final ensemble combines GNN, BERT, and XGBoost outputs using a 3-layer MLP with dimensions [384, 128, 2]. Weights are optimized using cross-entropy loss with class weights inversely proportional to class frequency to handle imbalance (legitimate:fraudulent $\approx$ 47:1).

\subsubsection{Training Protocol}
Data is split temporally: transactions before October 2025 for training (70\%), October 2025 for validation (15\%), and November--December 2025 for testing (15\%). This temporal split ensures evaluation on truly future transactions. Training uses SGD with momentum 0.9, initial learning rate 0.01 with cosine annealing, weight decay $10^{-4}$. Batch size is 1024 for GNN, with each batch containing stratified samples (50\% fraudulent, 50\% legitimate) to address class imbalance during training. Data is shuffled at each epoch. Training terminates after 100 epochs or when validation loss fails to improve for 10 consecutive epochs.

\subsubsection{Hyperparameter Search}
We perform grid search over: learning rate $\in \{10^{-3}, 10^{-2}, 10^{-1}\}$, hidden dimensions $\in \{128, 256, 512\}$, attention heads $\in \{4, 8, 16\}$, and dropout $\in \{0.1, 0.3, 0.5\}$. Hyperparameters are selected based on validation F1-score. All reported results use optimal hyperparameters determined on validation data.

\section{Experimental Results}

\subsection{Detection Performance}

We evaluated CryptoGuard-LLM against five baseline methods: traditional rule-based systems, Random Forest, XGBoost, BERT-only classification, and GNN-only approaches. All experiments were conducted using 5-fold cross-validation with temporal splits to ensure models were evaluated on future transactions relative to training data. Fig.~\ref{fig:performance} presents the comparative performance results.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig2_performance.png}
\caption{Comparative performance of detection models across accuracy, F1-score, and recall metrics.}
\label{fig:performance}
\end{figure}

CryptoGuard-LLM achieves 96.8\% detection accuracy, representing a 5.6 percentage point improvement over the next best baseline (GNN-only at 91.2\%). More importantly for practical deployment, our system achieves 94.7\% recall, meaning it successfully identifies nearly 95\% of all fraudulent transactions while maintaining a false positive rate of only 3.2\%. This balance between sensitivity and specificity is critical for operational deployment where both missed fraud and excessive false alarms impose significant costs.

\begin{table}[!t]
\caption{Detailed Performance Metrics by Fraud Category}
\label{tab:performance}
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Fraud Type} & \textbf{Prec.} & \textbf{Recall} & \textbf{F1} & \textbf{Support} \\
\midrule
Rug Pulls & 97.2\% & 96.8\% & 97.0\% & 284,521 \\
Phishing & 95.8\% & 93.4\% & 94.6\% & 241,892 \\
Ponzi Schemes & 96.4\% & 94.9\% & 95.6\% & 178,234 \\
Exchange Hacks & 98.1\% & 97.2\% & 97.6\% & 148,762 \\
Ransomware & 94.3\% & 91.8\% & 93.0\% & 98,234 \\
\midrule
\textbf{Overall} & \textbf{96.8\%} & \textbf{94.7\%} & \textbf{95.2\%} & \textbf{993,127} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Statistical Significance}

To validate the statistical significance of our results, we performed paired t-tests comparing CryptoGuard-LLM against each baseline across 5 cross-validation folds. The improvement over GNN-only (the strongest baseline) is statistically significant ($p < 0.001$, Cohen's $d = 1.42$). We also computed 95\% confidence intervals for all metrics: accuracy [96.2\%, 97.4\%], precision [96.1\%, 97.5\%], recall [94.0\%, 95.4\%], and F1-score [94.6\%, 95.8\%]. McNemar's test confirms that the performance differences are not due to chance ($\chi^2 = 847.3$, $p < 0.0001$).

\subsection{Temporal Analysis}

To evaluate system performance over time and assess adaptation to evolving fraud patterns, we conducted a 12-month longitudinal study during 2025. Fig.~\ref{fig:temporal} illustrates the temporal dynamics of threat detection, false positive rates, and response times.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig3_temporal.png}
\caption{CryptoGuard-LLM detection metrics over the 12-month deployment period showing improvements in detection volume, reduction in false positives, and decreased response times.}
\label{fig:temporal}
\end{figure}

The system demonstrated continuous improvement through online learning mechanisms, with false positive rates declining from 89 per 10,000 transactions in January to 24 per 10,000 by December. Average response time for threat alerts decreased from 145 minutes to 32 minutes, enabling more effective intervention in time-sensitive fraud scenarios. Notably, the system successfully detected three previously unknown fraud patterns that emerged mid-year, demonstrating zero-shot generalization capabilities attributable to the LLM component's semantic understanding.

\subsection{Computational Efficiency}

Real-time fraud detection requires processing transactions within latency constraints imposed by blockchain confirmation times. Our system processes an average of 2,847 transactions per second on a cluster of eight NVIDIA A100 GPUs, with 95th percentile latency of 1.2 seconds. The modular architecture enables selective deployment of components based on available resources; a reduced configuration using only the GNN and ensemble classifier achieves 89.4\% accuracy while reducing computational requirements by 73\%.

\section{Societal Implications and Policy Discussion}

\subsection{Demographic Disparities in Fraud Victimization}

Our analysis of fraud victimization patterns reveals concerning demographic disparities that warrant attention from policymakers and consumer protection agencies. Through anonymized analysis of victim reports and recovery outcomes, we identified that retail investors with portfolios under \$10,000 are 3.4 times more likely to fall victim to rug pulls compared to larger investors, likely due to lower access to due diligence resources and greater susceptibility to high-return promises. Geographic analysis indicates that victims in regions with limited cryptocurrency regulation experience 67\% lower recovery rates.

Age-related patterns also emerged, with individuals over 55 being disproportionately targeted by impersonation scams involving fake customer support and recovery service fraud. These findings highlight the need for targeted educational interventions and protective mechanisms for vulnerable populations. Our framework includes an explainability module that generates plain-language warnings calibrated to user sophistication levels, representing one approach to addressing information asymmetries.

\begin{figure}[!t]
\centering
\includegraphics[width=\columnwidth]{figures/fig4_distribution.png}
\caption{Distribution of detected cryptocurrency threats by type (left) and financial losses by sector in 2025 (right).}
\label{fig:distribution}
\end{figure}

\subsection{Regulatory Implications}

The cross-jurisdictional nature of cryptocurrency transactions creates significant challenges for regulatory enforcement. Our framework addresses this through compliance reporting modules that automatically generate jurisdiction-specific suspicious activity reports conforming to Financial Action Task Force (FATF) recommendations. Integration with the Travel Rule compliance requires careful handling of personally identifiable information; we implement privacy-preserving analytics that enable regulatory reporting while minimizing data exposure through differential privacy techniques.

We recommend that regulators consider mandating baseline fraud detection capabilities for cryptocurrency exchanges and custodians, similar to requirements in traditional financial services. Open-source availability of detection frameworks like CryptoGuard-LLM could enable smaller market participants to achieve compliance without prohibitive investment in proprietary systems. Additionally, international coordination on threat intelligence sharing protocols would enhance the collective defense against cross-border fraud operations.

\subsection{Ethical Considerations and Limitations}

The deployment of AI-powered surveillance systems in financial contexts raises important ethical considerations. False positive classifications can result in legitimate transactions being blocked or accounts being frozen, causing material harm to innocent users. Our system includes human-in-the-loop mechanisms for high-impact decisions and provides affected parties with explanation interfaces and appeal processes. We acknowledge that no detection system can eliminate all fraud without also generating some false positives, and we advocate for transparent communication of error rates to users.

Privacy implications of transaction monitoring deserve careful consideration. While blockchain transactions are pseudonymous rather than anonymous, aggregation with external data sources can enable deanonymization. Our framework implements data minimization principles, retaining only features necessary for fraud detection and automatically purging raw transaction data after processing. Future work should explore federated learning approaches that enable collaborative threat detection without centralized data aggregation.

\section{Conclusion}

This paper has presented CryptoGuard-LLM, a comprehensive multi-modal deep learning framework for real-time cryptocurrency fraud detection. Through integration of Graph Neural Networks, Large Language Models, and ensemble machine learning methods, our system achieves 96.8\% detection accuracy with 94.7\% recall, significantly outperforming existing approaches. Beyond technical contributions, we have examined the societal implications of cryptocurrency fraud, identifying demographic disparities in victimization and proposing policy interventions to protect vulnerable populations.

The cryptocurrency ecosystem continues to evolve rapidly, and fraud tactics will inevitably adapt in response to detection capabilities. We view CryptoGuard-LLM not as a final solution but as a foundation for ongoing research into the co-evolution of attack and defense in digital asset markets. Future work will explore adversarial robustness, cross-chain detection capabilities, and integration with emerging blockchain technologies including layer-2 solutions and zero-knowledge proof systems.

Ultimately, achieving a secure cryptocurrency ecosystem requires collaboration across technical, regulatory, and social dimensions. We hope this work contributes to that collaborative effort by demonstrating the potential of AI-powered detection systems while honestly acknowledging their limitations and advocating for complementary policy measures to protect users from the evolving threat of cryptocurrency fraud.

\section*{Data Availability}

The anonymized transaction dataset and trained model weights are available upon reasonable request to qualified researchers, subject to data use agreements that prohibit deanonymization attempts. Code for the CryptoGuard-LLM framework is available at: \url{[GitHub repository URL to be inserted]}. Supplementary materials including detailed hyperparameter configurations, additional experimental results, and extended policy analysis are provided as online appendices.

\section*{Acknowledgment}

The authors would like to thank the anonymous reviewers for their constructive feedback that significantly improved this manuscript. We gratefully acknowledge Cornell University for providing computational resources and research infrastructure. Special thanks to the blockchain analytics community for making publicly available datasets that enabled portions of this research. We also thank the members of the cybersecurity research community whose open-source tools and published work informed our methodology. Any opinions, findings, and conclusions expressed in this material are those of the authors and do not necessarily reflect the views of the affiliated institutions.

\begin{thebibliography}{17}
\bibliographystyle{IEEEtran}

\bibitem{b1}
T. Burgess, ``A multi-jurisdictional perspective: To what extent can cryptocurrency be regulated?'' \textit{J. Economic Criminology}, vol. 5, Art. no. 100086, 2024.

\bibitem{b2}
Z. Chen, L. D. Van Khoa, E. N. Teoh, A. Nazir, E. K. Karber, and Y. S. Phee, ``Machine learning techniques for anti-money laundering (AML) solutions in suspicious transaction detection: A review,'' \textit{Knowl. Inf. Syst.}, vol. 57, no. 2, pp. 245--285, 2022.

\bibitem{b3}
O. Dib, Y. Nan, and Y. Liu, ``The role of transformer models in advancing blockchain technology: A systematic review,'' \textit{IEEE Access}, vol. 12, pp. 45678--45695, 2024.

\bibitem{b4}
K. Greshake, S. Abdelnabi, S. Mishra \textit{et al.}, ``Not what you signed up for: Compromising real-world LLM-integrated applications with indirect prompt injection,'' arXiv:2302.12173, 2023.

\bibitem{b5}
I. Hasanov, S. Virta, A. Hakkala, and J. Isoaho, ``Application of large language models in cybersecurity: A systematic literature review,'' \textit{IEEE Access}, vol. 12, pp. 93331--93352, 2024.

\bibitem{b6}
Y. Hu, A. Seneviratne, and K. Thilakarathna, ``Characterizing and detecting money laundering activities on the Bitcoin network,'' \textit{IEEE Trans. Inf. Forensics Security}, vol. 17, pp. 2391--2405, 2022.

\bibitem{b7}
Y. Jiang, W. Zhang, J. Pang \textit{et al.}, ``Transformers and large language models for efficient intrusion detection systems: A comprehensive survey,'' arXiv:2408.09344, 2024.

\bibitem{b8}
J. Liu, Y. Wang, X. Chen \textit{et al.}, ``Large language models in wireless application design: In-context learning-enhanced automatic network intrusion detection,'' \textit{IEEE Commun. Surveys Tuts.}, vol. 26, no. 3, pp. 1892--1920, 2024.

\bibitem{b9}
S. B. Masud, M. M. Rana, H. J. Sohag \textit{et al.}, ``Understanding financial transaction security through blockchain and machine learning for fraud detection,'' \textit{SSRN Electron. J.}, Dec. 2024.

\bibitem{b10}
N. H. Motlagh, S. H. Khajavi, and A. Jaribion, ``A comprehensive overview of large language models for cyber defences: Opportunities and directions,'' arXiv:2405.14487, 2024.

\bibitem{b11}
A. Pareja, G. Domeniconi, J. Chen \textit{et al.}, ``EvolveGCN: Evolving graph convolutional networks for dynamic graphs,'' in \textit{Proc. AAAI Conf. Artif. Intell.}, vol. 34, no. 4, pp. 5363--5370, 2020.

\bibitem{b12}
X. Qian, Y. Liu, H. Zhang \textit{et al.}, ``Exploring LLMs for malware detection: Review, framework design, and countermeasure approaches,'' arXiv:2409.07587, 2024.

\bibitem{b13}
P. Singh, R. Kumar, and A. Sharma, ``Anomaly detection in blockchain networks using isolation forests and local outlier factors,'' \textit{J. Netw. Comput. Appl.}, vol. 221, Art. no. 103847, 2024.

\bibitem{b14}
S. S. Taher, S. Y. Ameen, and J. M. Ahmed, ``Advanced fraud detection in blockchain transactions: An ensemble learning and explainable AI approach,'' \textit{Eng., Technol. Appl. Sci. Res.}, vol. 14, no. 1, pp. 12822--12830, 2024.

\bibitem{b15}
M. Weber, G. Domeniconi, J. Chen \textit{et al.}, ``Anti-money laundering in Bitcoin: Experimenting with graph convolutional networks for financial forensics,'' in \textit{Proc. KDD Workshop Anomaly Detection Finance}, 2019.

\bibitem{b16}
M. A. Zade, ``Evaluating machine learning models for cryptocurrency fraud detection: A comparative analysis,'' \textit{J. Financial Technol.}, vol. 8, no. 2, pp. 145--162, 2024.

\bibitem{b17}
J. Zhang, H. Bu, H. Wen \textit{et al.}, ``When LLMs meet cybersecurity: A systematic literature review,'' \textit{Cybersecurity}, vol. 8, Art. no. 14, 2025.

\end{thebibliography}

\begin{IEEEbiographynophoto}{Naga Sujitha Vummaneni}
(Senior Member, IEEE) received the B.Tech. degree in computer science and engineering. She is currently pursuing the MBA degree at Cornell University, Ithaca, NY, USA. She has over 10 years of experience in cloud security and infrastructure engineering at major technology companies including Google, Nike, eBay, and Cisco Systems. Her research interests include blockchain security, machine learning for cybersecurity, and financial crime prevention. She holds multiple certifications including AWS Certified Security and CISM.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Usha Ratnam Jammula}
(Member, IEEE) is an Independent Researcher specializing in machine learning applications for financial systems. Her research interests include deep learning, natural language processing, and fraud detection systems.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Ramesh Chandra Aditya Komperla}
(Senior Member, IEEE) is an Independent Researcher with expertise in distributed systems and blockchain technology. His research interests include graph neural networks, cryptocurrency security, and scalable machine learning systems.
\end{IEEEbiographynophoto}

\end{document}
